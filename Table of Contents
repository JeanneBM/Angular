Lesson 01: Installing Ansible

1.1 Understanding Ansible
1.2 Host Requirements 
1.3 Installing Ansible on the Control Node
1.4 Preparing Managed Nodes
1.5 Verifying Ansible Installation

Lesson 02: Setting up a Managed Environment 	

2.1 Setting up Static Inventory 
2.2 Understanding Dynamic Inventory
2.3 Understanding Ansible Configuration Files
2.4 Managing Ansible Configuration Files

Lesson 03: Using Ad Hoc Commands 	

3.1 Using Ad Hoc Commands
3.2 Understanding Ansible Modules
3.3 Using ansible-doc to get Module Documentation
3.4 Introducing Essential Ansible Modules

Lesson 04: Getting Started with Playbooks 	

4.1 Using YAML to Write Playbooks
4.2 Verifying Playbook Syntax 
4.3 Writing Multiple-Play Playbooks

Lesson 05: Working with Variables and Facts 	

5.1 Understanding Variables
5.2 Using Variables 
5.3 Understanding Variable Precedence
5.4 Managing Host Variables
5.5 Using Multi-valued Variables
5.6 Using Ansible Vault 
5.7 Working with Facts
5.8 Creating Custom Facts

Lesson 06: Using Task Control 	

6.1 Using Loops and Items 
6.2 Using Register Variables with Loops 
6.3 Using when to Run Tasks Conditionally
6.4 Testing Multiple Conditions 
6.5 Using Handlers 
6.6 Using Blocks

Understanding Ansible Blocks:
* A block is a logical group of tasks
* It can be used to control how tasks are executed
* One block can, for instance, be enabled using a single when
* Blocks can also be used in error condition handling 
	* Use block to define the main tasks to run
	* Use rescue to define tasks that run if tasks defined in the block fail
	* Use always to define tasks that will run, regardless of the success or failure of the block and rescue tasks
* Notice that items cannot be used on blocks


vim blocks.yml
ansible-playbook blocks.yml
vim blocks2.yml
ansible ansible2.example.com -m file -a "path=/var/www/html/index.html state=touch"
ansible-playbook blocks2.yml

---------------------------------------------------------------------------------------------------------------------------------------------

6.7 Dealing with Failures

Understanding Failure Handling:
* Ansible looks at the exit status of a task to determine whether it has failed 
* When any task fails, Ansible aborts that rest of the play on that host and continues with the next host
* Different solutions can be used to change that behavior
* Use ignore_errors in a task to ignore failures
* Use force_handlers to force a handler that has been triggered to run, even if (another) task fails

Defining Failure States:
* As Ansible only looks at the exit status of a failed task, it may think a task was successful where that is not the case
* To be more specific, use failed_when to specify what to look for in command output to recognize a failure

Using the fail Module:
* The failed_when keyword can be used in a task to identify when a task has failed
* The fail module can be used to print a message that informs why a task has failed 
* To use failed_when or fail, the result of the command must be registered and the registered variable output must be analyzed
* When using the fail module, the failing task must have ignore_errors set to yes


vim failure.yml
ansible-playbook failure.yml
vim failure2.yml
ansible-playbook failure2.yml

---------------------------------------------------------------------------------------------------------------------------------------------

6.8 Managing Changed Status

Handling Changed Status:
* Managing the changed status may be important, as handlers trigger on the changed status
* The result of a command can be registered and the registered variable can be scanned for specific text to determine that a change has occurred
* This allows Ansible to report a hanged status, where it normally would not, thus allowing handlers to be triggered
* Using changed_when is usable in two cases:
	* to allow handlers to run when a change would not normally trigger
	* to disable commands that run successful to report a changed status
	

vim changed.yml
ansible-playbook changed.yml

---------------------------------------------------------------------------------------------------------------------------------------------

Lesson 07: Deploying Files 	

7.1 Using Modules to Manipulate Files:

Common File Modules:
* Different Modules are avaliable for managing files:
	* lineinfile: ensures that a line is in a file, useful for changing a single line in a file
	* blockinline: manipulates multi-line blocks of text in files
	* copy: copies a file from a local or remote machine to a location on a managed host
	* fetch: used to fetch a file from a remote machine and store it on the management node
	* file: sets attributes to files and can also create and remove files, symbolic links and more
	

vim file.yml
ansible-doc file
ansible-doc stat
cd /tmp/ansible1.example.com

---------------------------------------------------------------------------------------------------------------------------------------------

7.2 Managing SELinux File Context

Managing SELinux Context:
* file: sets attributes to files, including SELinux context and can also create and remove files, symbolic links and more
* sefcontext: manages SELinux file context in the SELinux Policy (but not on files)
* Notice that file sets SELinux context directly on the file (like the chcon command) and not in the policy


vim selinux.yml
ansible-playbook selinux.yml
ansible all -m "ls -lZ /tmp/removeme"

---------------------------------------------------------------------------------------------------------------------------------------------

7.3 Using Jinja2 Templates

Understanding Jinja2 Templates:
* lineinfile and blockinline can be used to apply simple modifications to files
* For more advanced modifications,use Jinja2 templates
* While using templates,the target files are automatically customized using variables and facts
* In a Jinja2 template you will find muliple elements:
	* data
	* variables
	* expressions
	* control structures
* The variables in the template are replaced with their values when the Jinja2 template is rendered to the target file on the managed host
* If using variables, they can be specified using the vars section of the playbook

Avoiding Confusion When Using Templates:
* To prevent administrators from overwriting files that are managed by Ansible, set the ansible_managed string:
	* First, in ansible.cfg set ansible_managed = Ansible managed
	* On top of the Jinja2 template, set the {{ ansible_managed }} variable

vim vsftpd-template.yml
vim vsftpd-template.j2
ansible-playbook vsftpd-template.yml
ansible all -a "cat /etc/vsftpd.conf"

---------------------------------------------------------------------------------------------------------------------------------------------

7.4 Using Control Structures in Jinja2

Using Control Structures in Templates:
* In Jinja2 templates, control structures can be used to organize the template in an optimal way
* The for statement can be used to iterate through a variable and use all values in the variable
* The if statement can be used to have the template work with a variable if another variable is defined


vim hostfile.yml
vim templates/hosts.j2
ansible-playbook hostsfile.yml
ansible ansible2.example.com -m command -a "cat /etc/hosts"
vim inventory
ansible-playbook hostsfile.yml

---------------------------------------------------------------------------------------------------------------------------------------------

Lesson 08: Using Ansible Roles 	

8.1 Understanding Directory Structure Best Practices 

~/myproject/ansible.cfg
			inventory-dev
			inventory-prod
			site.yml
			lamp.yml ------------------> * ~/.ansible/roles/nginx
						     * ~/.ansible/roles/httpd				
			file.yml ------------------> * ~/.ansible/roles/samba
						     * ~/.ansible/roles/nfs
			group-vars/lamp
					  /file
			host_vars
			
Organizing Ansible Contents:
* When working with Ansible, it's recommended to use project directories so that contents can be organized in a consistent way
* Each project directory may have its own ansible.cfg, inventory as well as playbooks 
* If the directory grows bigger, variable files and other include files may be used
* And finally, roles can be use to standardize and easily re-use specific parts of Ansible
* For now, consider a role a complete project dedicated to a specific task that is going to be included in the main playbook

Directory Layout Best Practices:
* Ansible Documentation describes best practices
  (https://docs.ansible.com/ansible/latest/user_guide/playbooks_best_practices.html)
  
* Some highlights:
	* On top in the directory, use site.yml as the master playbook
	* From site.yml, call specific playbooks for specifictypes of host (webservers.yml, dbservers.yml, etc.)
	* Consider using different inventory files to differentiate between production and staging phases 
	* Use groups_var/ and host_vars/ to set host related variables
	* Use roles to standardize common tasks
	
---------------------------------------------------------------------------------------------------------------------------------------------
 
8.2 Understanding Ansible Roles

Understanding Roles:
* Ansible Playbooks can be very similar: code used in one playbook can be useful in other playbooks also
* To make it easy to re-use code, roles can be used. A role is a collection of tasks, variables, files, templates and other resources 
in a fixed directory structure that, as such, can easily be included from a playbook
* Roles should be written in a generic way , such that play specific can be defined as variables in the play and overwrite the dafault 
variables that should be set in the role

Understanding Roles Default Structure:
* defaults contains default values of role variables. If variables are set at the play level as well, these default values are overwritten
* files my contain static files that are needed from the role tasks
* handlers has a main.yml taht defines handlers used in the role
* meta has a main.yml that may be used to include role metadata, such as information about author, license, dependencies and more
* tasks contains a main.yml that defines the role task definitions
* templates is used to store Jinja2 templates
* tests may contain an optional inventory file, as well as a test.yml playbook that can be used to test the role
* vars may contain a main.yml with standard variables for the role (which are not meant to be overwritten by playbook variables)

Understanding Role Variables:
* Variables can be defined at different levels in a role
* vars/main.yml has the role default variables, which are used in default role functioning. They are not intended to be overwritten 
* defaults/main.yml can contain dafault variables. These have a low precedence and can be overwritten by variables with the same name 
that are set in the playbook and which have higher precedence
* Playbook variables will always overwrite the variables as set in the role. Site-specific variables such as secrets and vault encrypted 
data should always be managed from the playbook, as role variables are intended to be generic
* Role variables are defined in the playbook when calling the role and they have the highest precedence and overwrite playbook variables 
as well as inventory variables

Understanding Role Location:
* Roles can be obtained in many ways:
	* You can write your own roles
	* For Red Hat Enterprise Linux, the rhel-system-roles package is avaliable
	* The community provides roles through the Ansible Galaxy website
* Roles can be stored at a default location and from there can easily be used from playbooks:
	* ./roles has highest precedence
	* ~/.ansible/roles is checked after that
	* /etc/ansible/roles is checked next
	* /usr/share/ansible/roles is checked last


Using Roles in a Playbook:
* Roles are reffered to from playbooks
* When roles are used, they will run before any task that is defined in the playbook 

---
- name: role demo
  hosts: all
  roles: 
    - role1
	- role2
	
* When calling a role, role variables can be defined

---
- name: role variable demo
  hosts: all
  roles: 
    - role: role1
	- role: role2
	  var1: cow
	  var2: goat
	  
---------------------------------------------------------------------------------------------------------------------------------------------

8.3 Using Ansible Galaxy for Standard Roles

Using Ansible Galaxy:
* Administrators can define their own roles or standard roles can be used from Ansible Galaxy
* Ansible Galaxy is a public website where community provided roles are offered 
* Before writing your own roles, check Galaxy, you may get the roles from there
* An easy-to-use search interface is avaliable at galaxy.ansible.com


ansible-galaxy install geerlingguy.nginx
vim main.yml
cd geerlingguy.nginx
cd geerlingguy.nginx/tasks
vim setup-RedHat.yml
vim nginx-role.yml
ansible-playbook nginx-role.yml

---------------------------------------------------------------------------------------------------------------------------------------------

8.4 Using the Ansible Galaxy Command Line Tool

Using the Galaxy CLI Utility:
* ansible-galaxy serach: will search for roles
	* If an argument is provided, ansible-galaxy will serach for this argument in the role description
	* Use options --author, --platforms and --galaxy-tags to narrow down the search results
	* ansible-galaxy search 'wordpress' --platforms EL

* ansible-galaxy info: provides information about roles 
	* ansible-galaxy info bertvv.wordpress

* ansible-galaxy install: downloads a role and installs it in ~/.ansible/roles
* After download, these roles can be used in playbooks, like any other role

Managing Roles:
* ansible-galaxy list: shows installed roles
* ansible-galaxy remove: can be used to clean up and remove roles
* ansible-galaxy init creates a directory structure that can be used to start developing your own role:
	* It interacts with the Ansible Galaxy website API
	* Specify username and role name as arguments 
	* ansible-galaxy init user.myrole
	
Using a Requirements File:
* ansible-galaxy: can be used to install a list of roles based on definitions in a requirements file
* A requirements file is a yml file that defines a list of required roles that are specified using the src keyword
* The src keyword can contain the name of a role from Ansible Galaxy, or a URL to a custom location pointing to your own roles
* Create roles/requirements.yml in the projects directory to use it
* Always specify the optional version attribute, to avoid getting surprises when a newer version of a role has become avaliable.
- src: file:///opt/local/roles/myrole.tar
  name: myrole
  version: 1.0
* To install roles using a requirements file, use: ansible-galaxy install -r roles/requirements.yml
  

ansible-galaxy search 'wordpress' --platforms EL
ansible-galaxy info bertvv.wordpress
ansible-galaxy install bertvv.wordpress
vim wordpress.yml

vim roles/requirements.yml
ansible-galaxy install -r roles/requirements.yml -p roles
vim roles/requirements.yml
-> "- version: 2.7.0
    - name: nginx-2.7.0"
ansible-galaxy install -r roles/requirements.yml -p roles

---------------------------------------------------------------------------------------------------------------------------------------------
	
8.5 Creating Custom Roles

Creating Roles:
* To create your own roles, use ansible-galaxy init myrole to create the role directory structure
* Mind the location of the directory structure, you can put it in the local project directory, or in a directory that is accesible 
  for all projects
* Populate the required role files as discussed before

Creating Roles - Best Practices:
* Each role should have its own version control repository 
* Don't put sensitive information in the role, but in the local plybooks or Ansible Vault instead 
* Use ansible-galaxy init to create the role structure 
* Don't forget to edit the README.md and the meta/main.yml to contain documentation about your role
* Roles should be dedicated to one task/function. Use multiple roles to manage multiple tasks/functions.
* Have a look at existing (Galaxy) roles before starting to write your own

Defining Role Dependencies:
* The meta/main.yml can be used to define role dependencies
* Dependencies listed here will be installed automatically when this role is used 

Using Conditional Roles:
* Conditional roles call a role dynamically, using the include_role module 
	* This makes it so conditional roles are treated more as tasks 
* Conditional Roles can be combined with conditional statements:
	* This makes it so a role will only run if the conditional statement is true 
	* Use include_role in a task statement to do so
	
---
- hosts: lamp
  tasks:
  - include_role: 
      name: lamp
    when: "ansible_facts['os_family'] == 'RedHat'"
    

cd roles
ls
tree motd
cd motd
vim tasks/main.yml
vim templetes/motd.j2
vim defaults/main.yml
vim vars/main.yml
vim handlers/main.yml
rm -rf handlers/ vars/
tree
rm -rf tests/
vim meta/main.yml
vim README.md
cd .. / .. 
ls
vim motd-role.yml
ansible-playbook motd-role.yml
ansible ansible2.example.com -m shell -a 'cat /etc/motd'

---------------------------------------------------------------------------------------------------------------------------------------------

8.6 Managing Order of Execution 

Understanding Role Order of Execution:
* Role tasks are always executed before playbook tasks
* Next, playbook tasks are executed 
* And after playbook tasks, handlers are executed
* Use: pre_tasks to define playbook tasks that are to be executed before the tasks in a role:
	* If these tasks notify a handler, this handler is executed before as well
* The post_tasks keyword can be used to define playbook tasks that are executed after playbook tasks and roles


vim pretasks.yml
ansible-playbook pretasks.yml

---------------------------------------------------------------------------------------------------------------------------------------------

8.7 Understanding RHEL System Roles

* The rhel-system-roles package can be installed to provide some standard roles for RHEL 6.10 and later
* These roles are based on the community linux-system-roles and supported by Red Hat support 
* Use the rhel-system-roles to overcome the difference between configuration choices on RHEL 6,7, and 8

---------------------------------------------------------------------------------------------------------------------------------------------

Lesson 09: Using RHEL System Roles 	

9.1 Understanding RHEL System Roles

* RHEL system roles are provided to configure standard RHEL operations 
* RHEL system roles have been provided since RHEL 7.4, and can be used to configure RHEL 6.10 and later
* Install the rhel-system-roles package to use them
* RHEL system roles are derived from the Ansible Linux System Roles project, which is avaliable through Ansible Galaxy

Current RHEL System Roles:
* Currently, the following RHEL system roles are provided:
      * rhel-system-roles.kdump configurates the kdump crash recovery service 
      * rhel-system-roles.network configurates network interfaces
      * rhel-system-roles.selinux manages all aspects of SELinux
      * rhel-system-roles.timesync is used to set up Network Time Protocol or Precision Time Protocol
      * rhel-system-roles.postfix is used to configurate a host as a Postfix MTA
      * rhel-system-roles.firewall configurates a firewall
      * rhel-system-roles.tuned configurates the tuned service 
* Addiotional RHEL system roles are likely to be introduced

---------------------------------------------------------------------------------------------------------------------------------------------

9.2 Installing RHEL System Roles

* Use: yum install rhel-system-roles to install them 
* The roles are installed to the /usr/share/ansible/roles directory, notice that the upstream linux-system-roles name is provided 
  as a symbolic link to provide maximum compatibility
* Documentation of Ansible system roles is avaliable in /usr/share/doc/rhel-system-roles-<version>
* Look for example YAML files in the role directories


su -
yum search rhel-system-roles
yum install -y rhel-system-roles
rpm -ql rhel-system-roles
cd /usr/share/ansible/roles
ls
cd rhel-system-roles.selinux/
ls
tree

---------------------------------------------------------------------------------------------------------------------------------------------

9.3 Using the RHEL SELinux System Role

The RHEL system role for SELinux can do several things:
* Set enforcing or permissive mode
* Set SELinux file contexts 
* Run restorecon

Rebooting After Making Changes:
* In some cases, to apply SELinux changes (such as a switch between enabled and disabled mode), a reboot is required
* The SELinux role doesn't reboot hosts itself because it should be up to the administrator to do that
* The role will set the selinux_reboot_required variable to true, and fail if a reboot is required
* This is used in a block / rescue structure, where the play is failing if the variable is not set to true 
* If the variable is set to true, the host is rebooted and the role is started again 
* See sample code in example-selinux-playbook in the roles documentation

Setting SELinux Related Variables:
* To Configure SELinux from the role, set at least the following variables:
	* selinux_state
	* selinux_booleans
	* selinux_fcontexts
	* selinux_restore_dirs
	* selinux_ports
	
	
cd /usr/share/doc/rhel-system-roles/selinux
ls
less README.md
vim example-selinux-playbook.yml
cd /usr/share/ansible/
ls
cd roles
ls
cd rhel-system-roles.selinux/
tree
vim tasks/main.yml

---------------------------------------------------------------------------------------------------------------------------------------------

9.4 Using the RHEL TimeSync System Role 

Why Does it Make Sense?
* rhel-system-roles.timesync can be used to manage time synchronization
* As the timesync service is different between RHEL 6 and RHEL 7/8, it makes sense managing this functionality using a rhel-system-role

Using rhel-system-roles.timesync:
* The role itself is configured to work with different variables, of which timesync_ntp_servers is the most important one
* Items in this variable are made up of different attributes, of which two are common:
	* hostname: shows the hostname of the time server
	* iburst: specifies that fast iburst synchronization should be used
* The timezone variable is also important, and sets the current timezone to be used
* A default playbook is avaliable in /usr/share/doc/rhel-system-roles/timesync


vim /usr/share/doc/rhel-system-roles/timesync
vim /usr/share/doc/rhel-system-roles/timesync/example-timesync-playbook.yml
vim setuptime.yml
vim setuptime-light.yml
vim group_vars/servers/timesync.yml
vim inventory
ansible-playbook setupline-light.yml

---------------------------------------------------------------------------------------------------------------------------------------------

Lesson 10: Using Ansible in Large Environments 	

10.1 Managing Inventory

Understanding Inventory Options:
* A static inventory file can be used as a list of managed hosts
* Dynamic inventory can automatically discover hosts, by talking to an external host management system, such as FreeIPA, Active Directory, 
  Red Hat Satelite and more
* Also, multiple inventories can be used, for instance by putting multiple inventory files in a directory and use that as the source 
  of inventory

Managing Dynamic Inventory:
* Dynamic inventory scripts are avaliable for different environments
	* Check https://github.com/ansible/ansible/tree/devel/contrib/inventory
* They are used like static inventory files, through ansible.cfg, or using the -i option to the ansible[-playbook] command
* Instead of using community dynamic inventory scripts, you can also write your own

Writing Dynamic Inventory Scripts:
* The only requirement is that the script returns the inventory information in JSON format 
* To see the correct output format, use ansible-inventory --list on any inventory
* Scripts can be written in any language, but Python is common

Using Multiple Inventory Files:
* If the inventory specified is a directory, all inventory files in that directory are considered
* This includes as well as dynamic inventory
* Inventory files cannot be created with dependencies to other inventory files


ansible-inventory --list
vim pascal.py
./pascal.py --list

----------------------------------------------------------------------------------------------------------------------------------------------

10.2 Addressing Host Patterns 

Addressing Hosts:
* By default, hosts are addressed with their host name as specified in inventory
* IP addresses can also be used
* Host groups are common and are defined in inventory:
	* Group: all is implicit and doesn't have to be defined
	* Group: ungrouped is also implicit and addresses all hosts that are not members of a group
* If special characters are used, always put them between quotes to avoid the special character being interpreted by the shell

Addressing Hosts Wildcard Examples:
* -hosts: '*.example.com'
* -hosts: '192.168.*'
* -hosts: 'web*'
* -hosts: web1,db1,192.168.4.2
* -hosts: web,&eastcoast
* -hosts: web,!web1
* -hosts: all,!web

----------------------------------------------------------------------------------------------------------------------------------------------

10.3 Configuring Parallelism

Understanding Processing Order:
* Plays are executed in order on all hosts referred to, and normally Ansible will start the next task if this task successfully completed on all managed hosts
* Ansible can run on multiple managed hosts simultaneously, but by default the maximum number of simultaneous hosts is limited to five 
* Set forks=n in ansible.cfg to change the maximum number of simultaneous hosts
* Alternatively, use -f nn to specify the max number of forks as argument to the ansible[-playbook] command
* The dafault of 5 is very limited, so you can set this parameter much higher, in particular if most of the work is done on the managed hosts and not on the control mode

Managing Rolling Updates:
* The dafault behaviour of running one task on all hosts, and next proceed to the next task means that in cluster environments you may have all hosts temporarily being unavaliable
* Use the serial keyword in the playbook to run hosts through the entire play in batches

----------------------------------------------------------------------------------------------------------------------------------------------

10.4 Organizing Directory Structure

Understanding Inclusion:
* If playbooks grow larger, it is common to use modularity by using includes and imports
* Includes and imports can happen for playbooks as well as tasks 
* An include is a dynamic process; Ansible processes the contents of the included files at the moment that this import is reached 
* An import is a static process; Ansible preprocesses the imported file contents before teh actual play is started
	* Playbook imports must be defined at the beginning of the playbook, using: import_playbook
	
Including Tasks Files:
* A task file is a flat list of tasks
* Use: import_tasks to statically import a task file in the playbook, it will be included at the location where it is imported
* Use: include_tasks to dynamically include a task file
* Dynamically including tasks means that some features are not avaliable:
	* ansible-playbook --list-tasks will not show teh tasks
	* ansible-playbook --start-at-task doesn't work
	* You cannot trigger a handler in an imported task file from the main task file
* Best practice: store task files in a dedicated directory to make management easier 

When to Include Task Files:
* When modularity is required, for instance to differentiate between groups of tasks that need to be executed against specific host types
* When different groups of IT staff are responsible for different setup tasks 
* If a task needs to be executed only in specific cases

Using Variables for External Plays and Tasks:
* In the design, it is recommended to keep include files as generic as possible 
* Define variables independently from the playbook
	* in separate include files
	* using group_vars and host_vars
	* or using local facts
* This allows you to process different values on different groups of hosts, while still using the same playbook


vim includes.yml
vim install-and-setup.yml
ansible-playbook includes.yml

----------------------------------------------------------------------------------------------------------------------------------------------

Lesson 11: Troubleshooting Ansible 	

11.1 Managing Ansible Logs

Understanding Ansible Logging:
* By default Ansible is not configured to log its output anywhere 
* Set log_path in ansible.cfg to write logs to a specific destination
	* Create this file in the project directory, /var/log is not writable by the Ansible user and will only work when running the playbook 
          with sudo
* When using this, you should also use log rotation


vim ansible.cfg // "[defaults] ... " + "log_path = lesson11.log"
ansible-playbook vsftpd.yml
ls
less lesson11.log
ansible-playbook --syntax-check vsftpd.yml
vim vsftpd.yml

----------------------------------------------------------------------------------------------------------------------------------------------

11.2 Using the Debug Module

* Variables play an important role in playbooks
* The debug module is used to show values of variables in playbooks
* It can also be used to show messages in specific error situations 


ansible-doc debug
vim debugme.yml
ansible-playbook debugme.yml
ansible-playbook -v debugme.yml

----------------------------------------------------------------------------------------------------------------------------------------------

11.3 Using Check Mode

* Use ansible-playbook --check on a playbook to perform check mode; this will show what would happen when running the playbook without 
  actually changing anything 
	* Modules in the playbook must support check mode
	* Check mode doesn't always work well in conditionals
	
* Set: check_mode: yes within a task to always run that specific task in check mode
	* This is useful for checking individual tasks
	* When setting: check_mode: no, for a task, this task will never run in check mode
	* Notice that: check_mode: no, is new since Ansible 2.6, and replaces the: always_run: yes, option from earlier versions 

Using Check Mode on Templates:
* Add --diff to an Ansible playbook run to see differences that would be made by template files on a managed hosts
		* ansible-playbook --check --diff myplaybook.yml
		

ansible-playbook --check vsftpd.yml

----------------------------------------------------------------------------------------------------------------------------------------------

11.4 Using Modules for Troubleshooting and Testing 

Understanding Modules to Check:
* uri: checks content that is returned from a specific URL
* script: runs a script from the control node on the managed hosts
* stat: checks the status of files; use it to register a variable and next test to determine if a file exists
* assert: this module will fail with an error if a specific condition is not met

Understanding stat:
* The: stat module can be used to check on file status
* It returns a dictionary that contains a stat field which can have multiple values:
	* atime: last access time of the file
	* isdir: true if file is a directory
	* exists: true if file exists
	* size: size in bytes
	* and many more
	

vim bashversion.yml
ansible-playbook bashversion.yml
vim assertstat.yml
ansible-playbook assertstat.yml

----------------------------------------------------------------------------------------------------------------------------------------------

11.5 Troubleshooting Connection Issues

Understanding Connection Issues:
* Connection issues include the following 
	* Issues setting up the physical connection
	* Issues running tasks as teh target user

Analyzing Authentication Issues:
* Confirm the: remote_user setting and existence of remote user on the managed host
* Confirm host key setup
* Verify: become and become_user
* Check that sudo is configured correctly 

Connecting to Managed Hosts:
* When a host is avaliable at different IP addresses / names, you can use ansible_host in inventory to specify how to connect
* The ensures that the connection is made in a persistent way, using the right interface
* web.example.com ansible_host=192.168.4.100

Using Ad Hoc Commands to Test Connectivity:
* The ping module was developed to test connectivity
* Use the --become option to also test privilege escalation
	* ansible ansible1 -m ping
	* ansible ansible1 -m ping --become
* Use the command module to test different items:
	* ansible ansible1 -m command -a 'df'
	* ansible ansible1 -m command -a 'free -m'
	
	
ansible ansible1.example.com -m ping
ansible ansible1.example.com -m ping --become 
ansible all -m command -a 'df'
ansible all -m command -a 'free -m'
ansible all -m command -a 'df | grep sda' //failed
ansible all -m shell -a 'df | grep sda' //failed
ansible all -m shell -a 'df' 
ansible all -m shell -a 'df | grep nvme' 

----------------------------------------------------------------------------------------------------------------------------------------------

11.6 Analyzing Playbook Errors

Analyzing Playbooks:
* Start by reading output messages 
* Next, add verbosity using -v:
	* -v: the output data is displayed
	* -vv: output as well as input data is shown
	* -vvv: adds connection information
	* -vvvv: adds additional information, for instance, about scripts that are executed and the user who's running tasks
	
----------------------------------------------------------------------------------------------------------------------------------------------

11.7 Avoiding Errors in Playbook Best Practices

Best Practices:
* When developing Playbooks, some best practices should be applied 
* The: name of plays and tasks should make sense to clearly see what's happening 
* Include comments to clarify difficult bits
* Use white spaces to make playbooks mor readable
* Indentation is essential
* Keep playbooks simple and small
* Use includes when playbooks risk getting too big

----------------------------------------------------------------------------------------------------------------------------------------------

Lesson 12: Managing Software with Ansible 	

12.1 Understanding Modules Related to Software Management 

Understanding Software Management Tasks:
* To manage software on RHEL systems, different tasks need to be managed
* Systems need to be subscribed 
* Repositories and software channels need to be configured
* Software needs to be installed and removed

Understanding Software Management Modules:
* package: Distribution agnostic module to manage packages
* win_package: Manages packages on Windows
* apt: Manages packages on Ubuntu
* yum: Manages packages on RHEL
* yum_repository: Manages Yum repositories
* package_facts: Returns information about packages as facts
* rpm_key: Adds or removes GPG keys from an RPM package database
* redhat_subscription: Uses the subscription_manager command to manage subscriptions
* rhn_register: Managed Red Hat Network registration using: rhnreg_ks
* rhn_channel: Manages RHN Channel subscription
* Other modules are avaliable, see
 https://docs.ansible.com/ansible/latest/modules/list_of_packaging_modules.html for more information
 
----------------------------------------------------------------------------------------------------------------------------------------------

12.2 Implementing a Playbook to Manage Software


vim sw_mgmt_demo.yml
ansible-playbook sw_mgmt_demo.yml
ansible ansible2.example.com -a "cat /etc/yum.repos.d/lesson12" //failed
ansible ansible2.example.com -a "ls /etc/yum.repos.d/"
ansible ansible2.example.com -a "cat /etc/yum.repos.d/lesson12.repo" //ok

----------------------------------------------------------------------------------------------------------------------------------------------

Lesson 13: Managing Users 	

13.1 Understanding Modules Related to User Management
13.2 Implementing a Playbook to Manage Users
13.3 Managing Encrypted Passwords

Lesson 14: Managing Processes and Tasks 	

14.1 Understanding Modules for Managing Processes and Tasks
14.2 Implementing a Playbook to Manage Processes and Tasks

Lesson 15: Managing Storage 	

15.1 Understanding Modules for Managing Storage
15.2 Implementing a Playbook to Manage Storage

Lesson 16: Managing Networking
	
16.1 Using Network Roles for Network Management
16.2 Understanding Modules for Network Management
16.3 Using Ansible to Manage IPv6
